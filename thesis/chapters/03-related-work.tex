\chapter{Related Work}

In the last few years, DL-based methods have been successfully applied to various image inverse problems~\cite{DN,SR,IP} and achieve state-of-the-art results.
While these networks were traditionally trained in a supervised fashion, requiring clean target images, recent methods remove the dependency on clean data by leveraging self-supervision~\cite{SelfSupervisedDenoising}.
In this chapter, we give an overview of existing supervised and self-supervised denoising approaches, presenting key principles and discussing their limitations.

\section{Supervised Methods}

Traditional supervised methods typically employ a neural network~$f_\theta$ to learn a mapping from a noisy image~$y$ to its clean counterpart~$x$.
Therefore, a dataset of paired clean and noisy images, denoted $\{(y^{(i)},x^{(i)})\}_{i=1}^n$, is essential for the training process.
The corresponding optimization problem is given by
\begin{equation}\label{eq:N2C}
    \argmin_\theta \sum_{i=1}^{n} \norm{f_\theta(y^{(i)}) - x^{(i)}}_2^2.
\end{equation}
Zhang~et al.\ propose the denoising convolutional neural network (DnCNN)~\cite{DnCNN} which improves denoising performance by making use of residual learning, i.e., instead of directly predicting the clean image, it is trained to predict the noise in the noisy image.
The denoised image is then obtained as $\hat{x} = y - f_{\theta^*}(y)$ for optimized parameters~$\theta^*$.
However, depending on the problem setting, acquiring the needed clean data can be difficult or even impossible, for example in medical imaging or also in DAS\@.

To address this issue, Lehtinen~et al.\ propose Noise2Noise (N2N)~\cite{N2N}, which does not require any clean data.
Instead, it utilizes two independent noisy observations $y_1 = x + n_1$ and $y_2 = x + n_2$ of the same underlying clean signal $x$ as input and target, respectively.
The training objective then becomes
\begin{equation}\label{eq:N2N}
    \argmin_\theta \sum_{i=1}^{n} \norm{f_\theta(y_1^{(i)}) - y_2^{(i)}}_2^2.
\end{equation}
This method relies on the assumption that the noise is zero-mean, i.e., $\E{n} = 0$, which, due to linearity of expectation, implies that $\E{y} = x$.
Since the mean squared error (MSE) is a mean-seeking loss function, the network then learns to predict $x$ implicitly.
Given infinite data, the optimal solution is actually equivalent to the one obtained by training with clean targets.
Although N2N is often impractical in practice because the required noisy-noisy pairs are difficult to obtain, it led to the development of other self-supervised approaches.

\section{Self-Supervised Methods}\label{sec:self-supervised}

Self-supervised methods are trained similarly to traditional supervised methods, but they do not rely on externally-provided target values.
In the context of denoising, these approaches can be broadly categorized into two main strategies:
Noise2Noise-based methods use a training objective similar to the one given by Equation~(\ref{eq:N2N}); however they generate their own noisy-noisy training pairs from individual noisy inputs.
Blind-spot-based methods, on the other hand, exploit spatial correlations in the image using different masking strategies, either in the input or in the network architecture itself.

\subsection{Noise2Noise-Based Methods}

Noisier2Noise~\cite{Noisier2Noise} builds upon N2N, but unlike N2N, it does not require a set of paired noisy-noisy images.
Instead, it constructs these training pairs from individual noisy images only.
Given a noisy input $y$, it generates an even noisier image $z = y + m = x + n + m$, with additional independent noise $m$ following the same distribution as $n$.
Once again, it is optimized through Equation~(\ref{eq:N2N}), using $z$ as the input and $y$ as the target.
The authors argue that $\E{y|z} = x + \frac{n + m}{2}$, since $\E{n} = \E{m}$.  % TODO proof in appendix
Therefore, by the same reasoning as in N2N, given a sufficient amount of noisy images, the network should learn to predict the mean of $x$ and $z$, which can then be used to obtain the denoised estimate as $\hat{x} = 2f_{\theta^*}(z) - z$.
While this method removes the need for a paired dataset, it requires knowledge of the noise distribution in order to sample the additional noise, which often is not available in an unsupervised setting.

Another approach based on N2N is Neighbor2Neighbor~\cite{Neighbor2Neighbor}.
The key idea behind this method is to construct training pairs from the noisy input $y$ by leveraging spatial redundancy through a subsampling strategy:
$y$ is divided into $2 \times 2$ cells from each of which two neighboring pixels are randomly selected --- one pixel is assigned to the first subsampled image and the other to the second.
These subsampled images then build the noisy training pair.
As a result of the subsampling, unlike in N2N, the underlying clean signal $x$ is not exactly identical in the two noisy images.
To address this, the authors extend the training strategy given by Equation~(\ref{eq:N2N}) by using an additional regularization term that encourages minimizing differences between subsampled versions of the denoised estimate.

Zero-Shot Noise2Noise~\cite{ZS-N2N} takes this idea one step further by enabling training on just one single noisy image instead of a set of noisy images.
The term \textit{zero-shot} refers to a training setup where the model is supposed to make predictions for types of data it has never observed before without any training examples.
This approach employs a similar subsampling strategy to obtain input and target values.
In order to avoid overfitting to the noisy target, it makes use of residual learning, a symmetric loss and an additional regularization term enforcing consistency with respect to the order in which downsampling and inference are performed.

\subsection{Blind-Spot-Based Methods}

All blind-spot-based methods assume that noise is zero-mean and spatially independent, while the clean image signal exhibits spatial correlations.
The underlying key principle for all of them is that a network should predict the value of a given pixel in the denoised image without directly observing its noisy counterpart, hence the term \textit{blind-spot}.
Therefore, the network can only learn from the neighboring pixels, which --- under the assumption of independent noise --- do not carry any information about the noise affecting the target pixel, thus preventing the network from predicting a noisy image.

\begin{wrapfigure}{r}{0.48\textwidth}
    \centering
    \tdplotsetmaincoords{60}{115}
    \begin{tikzpicture}[tdplot_main_coords, scale=0.9]
        \fill[color=Apricot!40] (0,0,0) -- (5,0,0) -- (5,0,5) -- (0,0,5) -- cycle;
        \fill[color=Apricot!80] (2,0,2) -- (5,0,2) -- (5,0,5) -- (2,0,5) -- cycle;
        \foreach \i in {1,2,3,4} {
            \draw (0,0,\i) -- (5,0,\i);
            \draw (\i,0,0) -- (\i,0,5);
        }
        \draw[thick] (0,0,0) -- (5,0,0) -- (5,0,5) -- (0,0,5) -- cycle;

        \draw[dashed] (2,0,2) -- (-1+3,2,3);
        \draw[dashed] (5,0,2) -- (-1+4,2,3);
        \draw[dashed] (5,0,5) -- (-1+4,2,4);
        \draw[dashed] (2,0,5) -- (-1+3,2,4);

        \fill[color=Apricot!80] (-1+1,2,1) -- (-1+4,2,1) -- (-1+4,2,4) -- (-1+1,2,4) -- cycle;
        \fill[color=Maroon!60] (-1+3,2,3) -- (-1+4,2,3) -- (-1+4,2,4) -- (-1+3,2,4) -- cycle;
        \foreach \i in {1,2,3,4} {
            \draw (-1,2,\i) -- (-1+5,2,\i);
            \draw (-1+\i,2,0) -- (-1+\i,2,5);
        }
        \draw[thick] (-1,2,0) -- (-1+5,2,0) -- (-1+5,2,5) -- (-1,2,5) -- cycle;

        \draw[dashed] (-1+1,2,1) -- (-2+2,4,2);
        \draw[dashed] (-1+4,2,1) -- (-2+3,4,2);
        \draw[dashed] (-1+4,2,4) -- (-2+3,4,3);
        \draw[dashed] (-1+1,2,4) -- (-2+2,4,3);

        \fill[color=Maroon!60] (-2+2,4,2) -- (-2+3,4,2) -- (-2+3,4,3) -- (-2+2,4,3) -- cycle;
        \foreach \i in {1,2,3,4} {
            \draw (-2,4,\i) -- (-2+5,4,\i);
            \draw (-2+\i,4,0) -- (-2+\i,4,5);
        }
        \draw[thick] (-2,4,0) -- (-2+5,4,0) -- (-2+5,4,5) -- (-2,4,5) -- cycle;
    \end{tikzpicture}
    \caption{Receptive field in CNNs, using a $3 \times 3$ kernel.}\label{fig:receptive-field}
\end{wrapfigure}

Krull~et al.\ first introduce this concept in their Noise2Void (N2V) paper~\cite{N2V}.
The authors consider training a network to predict the center pixel of a single patch of the input image in a supervised fashion, using the actual pixel value as the target.
To prevent the network from simply learning the identity, they propose restricting the output pixel's receptive field by masking the center pixel.
The receptive field refers to the set of pixels in the input that influences a particular pixel in the output, as visualized in Figure~\ref{fig:receptive-field}.
However, this process is not feasible in practice, as a whole patch has to be processed to obtain a single output pixel.
In order to allow efficient training, they approximate this behavior by training on random patches, for each of which a fixed number of pixels are randomly replaced by local neighbors, using their respective original noisy values as targets.

In Noise2Self (N2S)~\cite{N2S}, Batson~et al.\ generalize this concept to sets of variables, instead of single pixels only, by introducing the notion of $\mathcal{J}$-invariance.
For a noisy input image~$y \in \R^m$, let $\mathcal{J}$ be a partition of the dimensions $\{1,\dots,m\}$.
For a subset of the dimensions~$J \in \mathcal{J}$, $x_J$ denotes $x$ restricted to the dimensions $J$.
A function $f: \R^m \rightarrow \R^m$ is said to be $\mathcal{J}$-invariant if, for each $J \in \mathcal{J}$, $f(x)_J$ does not depend on $x_J$, which implies that
\begin{equation}
    f(x)_J = f(x_{J^c})_J,
\end{equation}
where $J^c$ refers to the complement of $J$.
The training objective from Equation~(\ref{eq:N2C}) than becomes
\begin{equation}
    \argmin_\theta \sum_{i=1}^{n} \norm{f_\theta(y^{(i)}_{J^c})_J - y^{(i)}_J}_2^2.
\end{equation}
As in N2V, $x_{J^c}$ is obtained through a masking strategy; the main difference lies in the way the masked pixels are replaced.
While N2S directly uses random values, N2V chooses the replacement pixels randomly from local neighbors.

In Noise2Same~\cite{Noise2Same}, the authors demonstrate that, in practice, both N2V and N2S are not strictly $\mathcal{J}$-invariant and thus conclude that strict $\mathcal{J}$-invariance is not necessary for achieving good denoising performance.
Therefore, they propose to do without explicit manipulation of the receptive field and instead add a regularization term that encourages the network to learn an approximately $\mathcal{J}$-invariant mapping by itself.
Laine~et al.~\cite{BSN} choose a different approach; instead of relying on masking strategies, they directly manipulate the receptive field by adapting the network architecture itself.

In addition to the blind-spot-based  methods discussed so far, which are typically trained on datasets of noisy images, there also exist methods that operate in a zero-shot setting.
Self2Self~\cite{S2S} is one such method, which leverages dropout-based self-consistency for denoising.
During training, the network is applied to a single noisy image, and dropout is used to randomly disable certain parts of the network, forcing it to rely on other parts to predict the noisy pixels.
The network then learns to produce consistent outputs across different dropout-induced versions of the image, allowing it to suppress noise while maintaining the underlying structure.
