\documentclass[a4paper, 12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

% Set page size and margins
\usepackage[a4paper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage[colorlinks]{hyperref}

% Bibliography
\usepackage{biblatex}
\addbibresource{references.bib}

\title{\textbf{Zero-Shot Denoising of Distributed Acoustic Sensing Data using Deep Priors}}
\author{Jannik MÃ¤nzer}
\date{}

\begin{document}
\maketitle

In recent years, deep learning-based methods have been successfully applied to problems across many different fields
\cite{ImageNet, GAN, GPT3}, including solving various inverse problems. One such problem is image denoising, which aims
to recover a clean image $x$ from a noisy observation $y = x + n$, where $n$ represents the noise. There exist multiple
supervised approaches to solve this problem \cite{DnCNN, GCBD}, however most of them need large datasets of (un)paired
clean-noisy samples for the training process. While this might not be a problem for ordinary images, in different
domains, such as medical imaging or distributed acoustic sensing (DAS), acquiring such datasets can be difficult or even
impossible. This lead to the development of different self-supervised approaches, removing the need for clean samples.
However, a lot of these methods still require large datasets of noisy samples \cite{Noise2Noise}, make assumptions about
the underlying noise model \cite{Noisier2Noise}, or are not well suited for noise that is spatially correlated
\cite{Noise2Self}.

One exception to this is the deep image prior (DIP) \cite{DIP}, as it does not make any assumptions about the noise
model and is an untrained approach, meaning that it works on a single noisy sample and instead only relies on the deep
neural network structure in order to regularize the solution space. Our work can be divided into two main sections:

First of all, we are going to explain the general ideas behind DIP and highlight its differences in comparison with
other self-supervised approaches. Then we are going to implement DIP and verify its practicability on different image
denoising tasks in order to obtain a baseline for future experiments. After that, we are going to look at various follow
up papers that try to improve on the original DIP performance, for example with regard to early stopping
\cite{EarlyStopping, RethinkingDIP} or better weight initialization \cite{MetaDIP, EDIP}. We are going to implement
these improvements and compare them to our baseline.

In the second section, we are going to apply these methods to DAS data and deal with issues that might be specific to
the underlying noise model \cite{SelfMixed}. We are also going to experiment with different loss functions, combining
the DIP with existing self-supervised approaches \cite{DDIP, Noise2Self, Noise2Same}. Finally, we are going to run
comprehensive experiments on different DAS datasets, comparing our results to other deep-learning based methods
\cite{DAS-N2N, DAS-J-invariant, SelfMixed}, as well as classical, non-deep learning methods, e.g. BM3D \cite{BM3D}.

\printbibliography

\end{document}